{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31bde2e7-2a74-4bd5-bdec-3b8d532edbe5",
   "metadata": {},
   "source": [
    "# Remote data paths in the catalog\n",
    "\n",
    "<b>How does Kedro handle remote data paths defined in Data Catalog ?</b>\n",
    "\n",
    "Kedro relies on fsspec to read and save data from a variety of data stores including \n",
    "\n",
    "- Local file systems\n",
    "- Network file systems\n",
    "- Cloud object stores\n",
    "- Hadoop. \n",
    "\n",
    "When specifying a storage location in `filepath:`, you should provide a URL using the general form `protocol://path/to/data`. \n",
    "If no protocol is provided, the local file system is assumed (which is the same as `file://`).\n",
    "\n",
    "The following protocols are available:\n",
    "\n",
    "- Local or Network File System: `file://` - the local file system is default in the absence of any protocol, it also permits relative paths.\n",
    "- Hadoop File System (HDFS): `hdfs://user@server:port/path/to/data` - Hadoop Distributed File System, for resilient, \n",
    "replicated files within a cluster.\n",
    "- Amazon S3: `s3://my-bucket-name/path/to/data` - Amazon S3 remote binary store, often used with Amazon EC2, using the library s3fs.\n",
    "- S3 Compatible Storage: `s3://my-bucket-name/path/_to/data` - for example, MinIO, using the s3fs library.\n",
    "- Google Cloud Storage: `gcs://` - Google Cloud Storage, typically used with Google Compute resource using gcsfs (in development).\n",
    "- Azure Blob Storage / Azure Data Lake Storage Gen2: `abfs://` - Azure Blob Storage, typically used when working on an Azure environment.\n",
    "- HTTP(s): `http://` or `https://` for reading data directly from HTTP web servers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0998ea-a9a9-46ec-b497-c49097ed73d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile catalog.yml\n",
    "companies:\n",
    "  type: spark.SparkDataset\n",
    "  filepath: /Volumes/<user-catalog>/<schema>/<volume>/companies.csv\n",
    "  file_format: csv\n",
    "  load_args:\n",
    "    header: True\n",
    "    inferSchema: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e5259-2b14-4f46-a21a-08bfc156b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install hdfs s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacef38a-bf39-4c1b-8ba4-6f3f962f7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession (should be routed via databricks-connect)\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f5373-69c4-4abe-82b9-87ca1ad1fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kedro project context\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "conf_loader = OmegaConfigLoader(conf_source=\".\")\n",
    "catalog_conf = conf_loader.get(\"catalog\")\n",
    "catalog = DataCatalog.from_config(catalog_conf)\n",
    "\n",
    "# Load CSV from Unity Catalog Volumes via SparkDataSet\n",
    "df = catalog.load(\"companies\")  # Make sure catalog.yml uses SparkDataSet\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426b198-f882-4491-81df-4ba3118bfba1",
   "metadata": {},
   "source": [
    "## Example using MinIO:\n",
    "\n",
    "MinIO is an object storage solution that provides an Amazon Web Services S3-compatible API and supports all core S3 features. MinIO is built to deploy anywhere - public or private cloud, baremetal infrastructure, orchestrated environments, and edge infrastructure.\n",
    "\n",
    "Using docker on MacOS -\n",
    "\n",
    "```sh\n",
    "mkdir -p ~/minio/data\n",
    "\n",
    "docker run \\\n",
    "   -p 9000:9000 \\\n",
    "   -p 9001:9001 \\\n",
    "   --name minio \\\n",
    "   -v ~/minio/data:/data \\\n",
    "   -e \"MINIO_ROOT_USER=<edit-ROOTNAME>\" \\\n",
    "   -e \"MINIO_ROOT_PASSWORD=<edit-CHANGEME123>\" \\\n",
    "   quay.io/minio/minio server /data --console-address \":9001\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb42c124-c048-4bb3-9a86-f193615b62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if you have access\n",
    "# import s3fs\n",
    "\n",
    "# fs = s3fs.S3FileSystem(\n",
    "#     key=\"ROOTNAME\",\n",
    "#     secret=\"CHANGEME123\",\n",
    "#     client_kwargs={\"endpoint_url\": \"http://localhost:9000\"},\n",
    "# )\n",
    "\n",
    "# # List all buckets\n",
    "# print(fs.ls(\"/\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68825d11-daae-4c1d-9530-616e17b92777",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile catalog.yml\n",
    "companies:\n",
    "  type: pandas.CSVDataset\n",
    "  filepath: \"s3://kedro-databricks/companies.csv\"\n",
    "  credentials: minio\n",
    "  fs_args:\n",
    "    anon: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f27ef-d977-41ad-8239-be2ced8c32d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile credentials.yml\n",
    "minio:\n",
    "  key: <edit-ROOTNAME>\n",
    "  secret: <edit-CHANGEME123>\n",
    "  client_kwargs:\n",
    "    endpoint_url: http://localhost:9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce153776-0901-44ef-b060-de490343a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kedro project context\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "conf_loader = OmegaConfigLoader(conf_source=\".\")\n",
    "catalog_conf = conf_loader.get(\"catalog\")\n",
    "credentials_conf = conf_loader.get(\"credentials\")\n",
    "\n",
    "catalog = DataCatalog.from_config(catalog_conf, credentials_conf)\n",
    "\n",
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09219a5-1838-4f08-908d-f6fdcc96983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = catalog.load(\"companies\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a34ec4-0abb-4614-9384-33baee611e1a",
   "metadata": {},
   "source": [
    "<b>References</b>\n",
    "\n",
    "- Dataset filepath: https://docs.kedro.org/en/latest/data/data_catalog.html#dataset-filepath\n",
    "- Dataset access credentials: https://docs.kedro.org/en/latest/data/data_catalog.html#dataset-access-credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c4dbd-8ef9-46b1-8f72-459e63ab7c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
